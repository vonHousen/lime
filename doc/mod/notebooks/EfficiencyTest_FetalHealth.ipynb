{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.ensemble\n",
    "import os.path\n",
    "import sklearn.neural_network\n",
    "import sklearn.svm\n",
    "import sklearn.naive_bayes\n",
    "import sklearn.tree\n",
    "import lime.lime_tabular_mod\n",
    "import lime.lime_tabular_multiregressor\n",
    "import lime.lime_tabular_multiclassifier\n",
    "import lime.lime_tabular_singleclassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import doc.mod.utils.DatasetRepository as dr\n",
    "import doc.mod.utils.ResultsProcessing as rp\n",
    "from tqdm import tqdm\n",
    "\n",
    "repo = dr.DatasetRepository(\"../data\")\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"mode.chained_assignment\", None)\n",
    "plt.style.use({\"figure.facecolor\": \"white\"})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# Dataset: Fetal Health"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "labels_count = 3\n",
    "bins_count = 30\n",
    "version_str = \"v3\"\n",
    "dataset_name = \"FetalHealth\"\n",
    "dataset = repo.get_fetal_health_dataset(random_state=42)\n",
    "dataset.train_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Train different classifiers on the selected dataset (with their default settings)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "models = [\n",
    "    (\"Random Forest\", sklearn.ensemble.RandomForestClassifier(n_jobs=-1)),\n",
    "    (\"AdaBoost\", sklearn.ensemble.AdaBoostClassifier()),\n",
    "    (\"DecisionTree\", sklearn.tree.DecisionTreeClassifier()),\n",
    "    (\"Neural Network\", sklearn.neural_network.MLPClassifier()),\n",
    "    # (\"SVM\", sklearn.svm.LinearSVC()), do not provide predict_proba\n",
    "    (\"Naive Bayes\", sklearn.naive_bayes.GaussianNB()),\n",
    "    (\"kNN\", sklearn.neighbors.KNeighborsClassifier())\n",
    "]\n",
    "precision_for_classifier = {}\n",
    "recall_for_classifier = {}\n",
    "f1_for_classifier = {}\n",
    "for (classifier_name, model) in models:\n",
    "    x = dataset.train_data.to_numpy()\n",
    "    y = dataset.train_labels.to_numpy()\n",
    "    model.fit(x, y)\n",
    "\n",
    "    x = dataset.test_data.to_numpy()\n",
    "    y_true = dataset.test_labels.to_numpy()\n",
    "    y_predicted = model.predict(x)\n",
    "\n",
    "    precision_for_classifier[classifier_name] = sklearn.metrics.precision_score(y_true=y_true, y_pred=y_predicted, average=\"macro\")\n",
    "    recall_for_classifier[classifier_name] = sklearn.metrics.recall_score(y_true=y_true, y_pred=y_predicted, average=\"macro\")\n",
    "    f1_for_classifier[classifier_name] = sklearn.metrics.f1_score(y_true=y_true, y_pred=y_predicted, average=\"macro\")\n",
    "\n",
    "test_data_subset = dataset.test_data.to_numpy()\n",
    "\n",
    "test_instances_count = test_data_subset.shape[0]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,4))\n",
    "plt.bar(f1_for_classifier.keys(), f1_for_classifier.values(), width=0.5)\n",
    "plt.title(\"f1_score\")\n",
    "plt.grid(axis=\"y\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "## Use original LIME to explain classifiers' predictions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results_file_default = f\"saved_results/{dataset_name}/default_results_{version_str}\"\n",
    "if os.path.isfile(results_file_default + \".npy\"):\n",
    "    postprocessor_default = rp.ResultsProcessing.from_file(\n",
    "        results_file_default,\n",
    "        models,\n",
    "        labels_count\n",
    "    )\n",
    "\n",
    "else:\n",
    "    scores_for_surrogate_model_default = \\\n",
    "        np.empty(shape=(len(models), test_instances_count, labels_count), dtype=\"float32\")\n",
    "    losses_for_surrogate_model_default = \\\n",
    "        np.empty(shape=(len(models), test_instances_count, labels_count), dtype=\"float32\")\n",
    "    losses_mean_for_cv_model_default = \\\n",
    "        np.empty(shape=(len(models), test_instances_count, labels_count), dtype=\"float32\")\n",
    "    losses_std_for_cv_model_default = \\\n",
    "        np.empty(shape=(len(models), test_instances_count, labels_count), dtype=\"float32\")\n",
    "    fidelity_loss_on_explanation_default = \\\n",
    "        np.empty(shape=(len(models), test_instances_count,), dtype=\"float32\")\n",
    "    fidelity_loss_on_generated_data_default = \\\n",
    "        np.empty(shape=(len(models), test_instances_count,), dtype=\"float32\")\n",
    "    fidelity_loss_on_kfold_mean_default = \\\n",
    "        np.empty(shape=(len(models), test_instances_count,), dtype=\"float32\")\n",
    "    fidelity_loss_on_kfold_std_default = \\\n",
    "        np.empty(shape=(len(models), test_instances_count,), dtype=\"float32\")\n",
    "    fidelity_loss_distribution_quantiles_default = \\\n",
    "        np.empty(shape=(len(models), test_instances_count, bins_count), dtype=\"float32\")\n",
    "\n",
    "    for model_idx, (classifier_name, model) in enumerate(models):\n",
    "\n",
    "        explainer_default = lime.lime_tabular_mod.LimeTabularExplainerMod(\n",
    "            dataset.train_data.to_numpy(),\n",
    "            feature_names = dataset.train_data.columns.to_list(),\n",
    "            class_names = model.classes_,\n",
    "            discretize_continuous=False,\n",
    "            sample_around_instance=True,\n",
    "            categorical_features=dataset.categorical_features,\n",
    "            with_kfold=5\n",
    "        )\n",
    "\n",
    "        for instance_idx, test_instance in enumerate(tqdm(\n",
    "                    test_data_subset,\n",
    "                    desc=f\"{classifier_name}\",\n",
    "                    bar_format=\"{desc:<20}{percentage:3.0f}%|{bar}{r_bar}\"\n",
    "        )):\n",
    "\n",
    "            explanation = explainer_default.explain_instance(\n",
    "                test_instance.reshape(-1),\n",
    "                model.predict_proba,\n",
    "                num_features = 4,\n",
    "                top_labels = labels_count,\n",
    "                distance_metric=\"minkowski\",\n",
    "                minkowski_norm=100.\n",
    "            )\n",
    "            scores_for_surrogate_model_default[model_idx, instance_idx, :] = \\\n",
    "                explanation.get_scores_for_surrogate_model()\n",
    "            losses_for_surrogate_model_default[model_idx, instance_idx, :] = \\\n",
    "                explanation.get_losses_for_surrogate_model()\n",
    "            losses_mean_for_cv_model_default[model_idx, instance_idx, :] = \\\n",
    "                explanation.get_losses_for_cv_model(out=\"mean\")\n",
    "            losses_std_for_cv_model_default[model_idx, instance_idx, :] = \\\n",
    "                explanation.get_losses_for_cv_model(out=\"std\")\n",
    "            fidelity_loss_on_explanation_default[model_idx, instance_idx] = \\\n",
    "                explanation.get_fidelity_loss_on_explanation()\n",
    "            fidelity_loss_on_generated_data_default[model_idx, instance_idx] = \\\n",
    "                explanation.get_fidelity_loss_on_generated_data()\n",
    "            fidelity_loss_on_kfold_mean_default[model_idx, instance_idx] = \\\n",
    "                explanation.get_fidelity_loss_on_kfold(out=\"mean\")\n",
    "            fidelity_loss_on_kfold_std_default[model_idx, instance_idx] = \\\n",
    "                explanation.get_fidelity_loss_on_kfold(out=\"std\")\n",
    "            fidelity_loss_distribution_quantiles_default[model_idx, instance_idx, :] = \\\n",
    "                explanation.get_fidelity_loss_distribution(quantiles=bins_count)\n",
    "\n",
    "    postprocessor_default = rp.ResultsProcessing(\n",
    "        models,\n",
    "        labels_count,\n",
    "        scores_for_surrogate_model_default,\n",
    "        losses_for_surrogate_model_default,\n",
    "        losses_mean_for_cv_model_default,\n",
    "        losses_std_for_cv_model_default,\n",
    "        fidelity_loss_on_explanation_default,\n",
    "        fidelity_loss_on_generated_data_default,\n",
    "        fidelity_loss_on_kfold_mean_default,\n",
    "        fidelity_loss_on_kfold_std_default,\n",
    "        fidelity_loss_distribution_quantiles_default\n",
    "    )\n",
    "    postprocessor_default.save_results(results_file_default)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "postprocessor_default.plot_scores_for_surrogate_model()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "postprocessor_default.plot_losses_for_surrogate_model()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "postprocessor_default.plot_fidelity_loss_on_explanation()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "postprocessor_default.plot_fidelity_losses_on_generated_data()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "postprocessor_default.plot_fidelity_loss_distribution(domain_unit=\"Quantiles\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "## Use modified LIME to explain classifiers' predictions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "### Use multiple Regression Trees as local surrogate"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results_file_multiregression = f\"saved_results/{dataset_name}/multiregression_results_{version_str}\"\n",
    "if os.path.isfile(results_file_multiregression + \".npy\"):\n",
    "    postprocessor_multiregression = rp.ResultsProcessing.from_file(\n",
    "        results_file_multiregression,\n",
    "        models,\n",
    "        labels_count\n",
    "    )\n",
    "\n",
    "else:\n",
    "    scores_for_surrogate_model_multiregression = \\\n",
    "        np.empty(shape=(len(models), test_instances_count, labels_count), dtype=\"float32\")\n",
    "    losses_for_surrogate_model_multiregression = \\\n",
    "        np.empty(shape=(len(models), test_instances_count, labels_count), dtype=\"float32\")\n",
    "    losses_mean_for_cv_model_multiregression = \\\n",
    "        np.empty(shape=(len(models), test_instances_count, labels_count), dtype=\"float32\")\n",
    "    losses_std_for_cv_model_multiregression = \\\n",
    "        np.empty(shape=(len(models), test_instances_count, labels_count), dtype=\"float32\")\n",
    "    fidelity_loss_on_explanation_multiregression = \\\n",
    "        np.empty(shape=(len(models), test_instances_count,), dtype=\"float32\")\n",
    "    fidelity_loss_on_generated_data_multiregression = \\\n",
    "        np.empty(shape=(len(models), test_instances_count,), dtype=\"float32\")\n",
    "    fidelity_loss_on_kfold_mean_multiregression = \\\n",
    "        np.empty(shape=(len(models), test_instances_count,), dtype=\"float32\")\n",
    "    fidelity_loss_on_kfold_std_multiregression = \\\n",
    "        np.empty(shape=(len(models), test_instances_count,), dtype=\"float32\")\n",
    "    fidelity_loss_distribution_quantiles_multiregression = \\\n",
    "        np.empty(shape=(len(models), test_instances_count, bins_count), dtype=\"float32\")\n",
    "\n",
    "    for model_idx, (classifier_name, model) in enumerate(models):\n",
    "\n",
    "        explainer_multiregression = lime.lime_tabular_multiregressor.LTEMultiRegressionTree(\n",
    "            dataset.train_data.to_numpy(),\n",
    "            feature_names = dataset.train_data.columns.to_list(),\n",
    "            class_names = model.classes_,\n",
    "            discretize_continuous=False,\n",
    "            sample_around_instance=True,\n",
    "            categorical_features=dataset.categorical_features,\n",
    "            with_kfold=5\n",
    "        )\n",
    "\n",
    "        for instance_idx, test_instance in enumerate(tqdm(\n",
    "                    test_data_subset,\n",
    "                    desc=f\"{classifier_name}\",\n",
    "                    bar_format=\"{desc:<20}{percentage:3.0f}%|{bar}{r_bar}\"\n",
    "        )):\n",
    "\n",
    "            explanation = explainer_multiregression.explain_instance(\n",
    "                test_instance.reshape(-1),\n",
    "                model.predict_proba,\n",
    "                num_features = 4,\n",
    "                top_labels = labels_count,\n",
    "                distance_metric=\"minkowski\",\n",
    "                minkowski_norm=100.\n",
    "            )\n",
    "            scores_for_surrogate_model_multiregression[model_idx, instance_idx, :] = \\\n",
    "                explanation.get_scores_for_surrogate_model()\n",
    "            losses_for_surrogate_model_multiregression[model_idx, instance_idx, :] = \\\n",
    "                explanation.get_losses_for_surrogate_model()\n",
    "            losses_mean_for_cv_model_multiregression[model_idx, instance_idx, :] = \\\n",
    "                explanation.get_losses_for_cv_model(out=\"mean\")\n",
    "            losses_std_for_cv_model_multiregression[model_idx, instance_idx, :] = \\\n",
    "                explanation.get_losses_for_cv_model(out=\"std\")\n",
    "            fidelity_loss_on_explanation_multiregression[model_idx, instance_idx] = \\\n",
    "                explanation.get_fidelity_loss_on_explanation()\n",
    "            fidelity_loss_on_generated_data_multiregression[model_idx, instance_idx] = \\\n",
    "                explanation.get_fidelity_loss_on_generated_data()\n",
    "            fidelity_loss_on_kfold_mean_multiregression[model_idx, instance_idx] = \\\n",
    "                explanation.get_fidelity_loss_on_kfold(out=\"mean\")\n",
    "            fidelity_loss_on_kfold_std_multiregression[model_idx, instance_idx] = \\\n",
    "                explanation.get_fidelity_loss_on_kfold(out=\"std\")\n",
    "            fidelity_loss_distribution_quantiles_multiregression[model_idx, instance_idx, :] = \\\n",
    "                explanation.get_fidelity_loss_distribution(quantiles=bins_count)\n",
    "\n",
    "    postprocessor_multiregression = rp.ResultsProcessing(\n",
    "        models,\n",
    "        labels_count,\n",
    "        scores_for_surrogate_model_multiregression,\n",
    "        losses_for_surrogate_model_multiregression,\n",
    "        losses_mean_for_cv_model_multiregression,\n",
    "        losses_std_for_cv_model_multiregression,\n",
    "        fidelity_loss_on_explanation_multiregression,\n",
    "        fidelity_loss_on_generated_data_multiregression,\n",
    "        fidelity_loss_on_kfold_mean_multiregression,\n",
    "        fidelity_loss_on_kfold_std_multiregression,\n",
    "        fidelity_loss_distribution_quantiles_multiregression\n",
    "    )\n",
    "    postprocessor_multiregression.save_results(results_file_multiregression)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "postprocessor_multiregression.plot_scores_for_surrogate_model()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "postprocessor_multiregression.plot_losses_for_surrogate_model()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "postprocessor_multiregression.plot_fidelity_loss_on_explanation()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "postprocessor_multiregression.plot_fidelity_losses_on_generated_data()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "postprocessor_multiregression.plot_fidelity_loss_distribution(domain_unit=\"Quantiles\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "### Use multiple Decision Trees as local surrogate"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results_file_multiclassifier = f\"saved_results/{dataset_name}/multiclassifier_results_{version_str}\"\n",
    "if os.path.isfile(results_file_multiclassifier + \".npy\"):\n",
    "    postprocessor_multiclassifier = rp.ResultsProcessing.from_file(\n",
    "        results_file_multiclassifier,\n",
    "        models,\n",
    "        labels_count\n",
    "    )\n",
    "\n",
    "else:\n",
    "    scores_for_surrogate_model_multiclassifier = \\\n",
    "        np.empty(shape=(len(models), test_instances_count, labels_count), dtype=\"float32\")\n",
    "    losses_for_surrogate_model_multiclassifier = \\\n",
    "        np.empty(shape=(len(models), test_instances_count, labels_count), dtype=\"float32\")\n",
    "    losses_mean_for_cv_model_multiclassifier = \\\n",
    "        np.empty(shape=(len(models), test_instances_count, labels_count), dtype=\"float32\")\n",
    "    losses_std_for_cv_model_multiclassifier = \\\n",
    "        np.empty(shape=(len(models), test_instances_count, labels_count), dtype=\"float32\")\n",
    "    fidelity_loss_on_explanation_multiclassifier = \\\n",
    "        np.empty(shape=(len(models), test_instances_count,), dtype=\"float32\")\n",
    "    fidelity_loss_on_generated_data_multiclassifier = \\\n",
    "        np.empty(shape=(len(models), test_instances_count,), dtype=\"float32\")\n",
    "    fidelity_loss_on_kfold_mean_multiclassifier = \\\n",
    "        np.empty(shape=(len(models), test_instances_count,), dtype=\"float32\")\n",
    "    fidelity_loss_on_kfold_std_multiclassifier = \\\n",
    "        np.empty(shape=(len(models), test_instances_count,), dtype=\"float32\")\n",
    "    fidelity_loss_distribution_quantiles_multiclassifier = \\\n",
    "        np.empty(shape=(len(models), test_instances_count, bins_count), dtype=\"float32\")\n",
    "\n",
    "    for model_idx, (classifier_name, model) in enumerate(models):\n",
    "\n",
    "        explainer_multiregression = lime.lime_tabular_multiclassifier.LTEMultiDecisionTree(\n",
    "            dataset.train_data.to_numpy(),\n",
    "            feature_names = dataset.train_data.columns.to_list(),\n",
    "            class_names = model.classes_,\n",
    "            discretize_continuous=False,\n",
    "            sample_around_instance=True,\n",
    "            categorical_features=dataset.categorical_features,\n",
    "            with_kfold=5\n",
    "        )\n",
    "\n",
    "        for instance_idx, test_instance in enumerate(tqdm(\n",
    "                    test_data_subset,\n",
    "                    desc=f\"{classifier_name}\",\n",
    "                    bar_format=\"{desc:<20}{percentage:3.0f}%|{bar}{r_bar}\"\n",
    "        )):\n",
    "\n",
    "            explanation = explainer_multiregression.explain_instance(\n",
    "                test_instance.reshape(-1),\n",
    "                model.predict_proba,\n",
    "                num_features = 4,\n",
    "                top_labels = labels_count,\n",
    "                distance_metric=\"minkowski\",\n",
    "                minkowski_norm=100.\n",
    "            )\n",
    "            scores_for_surrogate_model_multiclassifier[model_idx, instance_idx, :] = \\\n",
    "                explanation.get_scores_for_surrogate_model()\n",
    "            losses_for_surrogate_model_multiclassifier[model_idx, instance_idx, :] = \\\n",
    "                explanation.get_losses_for_surrogate_model()\n",
    "            losses_mean_for_cv_model_multiclassifier[model_idx, instance_idx, :] = \\\n",
    "                explanation.get_losses_for_cv_model(out=\"mean\")\n",
    "            losses_std_for_cv_model_multiclassifier[model_idx, instance_idx, :] = \\\n",
    "                explanation.get_losses_for_cv_model(out=\"std\")\n",
    "            fidelity_loss_on_explanation_multiclassifier[model_idx, instance_idx] = \\\n",
    "                explanation.get_fidelity_loss_on_explanation()\n",
    "            fidelity_loss_on_generated_data_multiclassifier[model_idx, instance_idx] = \\\n",
    "                explanation.get_fidelity_loss_on_generated_data()\n",
    "            fidelity_loss_on_kfold_mean_multiclassifier[model_idx, instance_idx] = \\\n",
    "                explanation.get_fidelity_loss_on_kfold(out=\"mean\")\n",
    "            fidelity_loss_on_kfold_std_multiclassifier[model_idx, instance_idx] = \\\n",
    "                explanation.get_fidelity_loss_on_kfold(out=\"std\")\n",
    "            fidelity_loss_distribution_quantiles_multiclassifier[model_idx, instance_idx, :] = \\\n",
    "                explanation.get_fidelity_loss_distribution(quantiles=bins_count)\n",
    "\n",
    "    postprocessor_multiclassifier = rp.ResultsProcessing(\n",
    "        models,\n",
    "        labels_count,\n",
    "        scores_for_surrogate_model_multiclassifier,\n",
    "        losses_for_surrogate_model_multiclassifier,\n",
    "        losses_mean_for_cv_model_multiclassifier,\n",
    "        losses_std_for_cv_model_multiclassifier,\n",
    "        fidelity_loss_on_explanation_multiclassifier,\n",
    "        fidelity_loss_on_generated_data_multiclassifier,\n",
    "        fidelity_loss_on_kfold_mean_multiclassifier,\n",
    "        fidelity_loss_on_kfold_std_multiclassifier,\n",
    "        fidelity_loss_distribution_quantiles_multiclassifier\n",
    "    )\n",
    "    postprocessor_multiclassifier.save_results(results_file_multiclassifier)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "postprocessor_multiclassifier.plot_scores_for_surrogate_model()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "postprocessor_multiclassifier.plot_losses_for_surrogate_model()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "postprocessor_multiclassifier.plot_fidelity_loss_on_explanation()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "postprocessor_multiclassifier.plot_fidelity_losses_on_generated_data()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "postprocessor_multiclassifier.plot_fidelity_loss_distribution(domain_unit=\"Quantiles\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "### Use single Decision Tree as local surrogate"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results_file_singleclassifier = f\"saved_results/{dataset_name}/singleclassifier_results_{version_str}\"\n",
    "if os.path.isfile(results_file_singleclassifier + \".npy\"):\n",
    "    postprocessor_singleclassifier = rp.ResultsProcessing.from_file(\n",
    "        results_file_singleclassifier,\n",
    "        models,\n",
    "        labels_count\n",
    "    )\n",
    "\n",
    "else:\n",
    "    scores_for_surrogate_model_singleclassifier = \\\n",
    "        np.empty(shape=(len(models), test_instances_count, labels_count), dtype=\"float32\")\n",
    "    losses_for_surrogate_model_singleclassifier = \\\n",
    "        np.empty(shape=(len(models), test_instances_count, labels_count), dtype=\"float32\")\n",
    "    losses_mean_for_cv_model_singleclassifier = \\\n",
    "        np.empty(shape=(len(models), test_instances_count, labels_count), dtype=\"float32\")\n",
    "    losses_std_for_cv_model_singleclassifier = \\\n",
    "        np.empty(shape=(len(models), test_instances_count, labels_count), dtype=\"float32\")\n",
    "    fidelity_loss_on_explanation_singleclassifier = \\\n",
    "        np.empty(shape=(len(models), test_instances_count,), dtype=\"float32\")\n",
    "    fidelity_loss_on_generated_data_singleclassifier = \\\n",
    "        np.empty(shape=(len(models), test_instances_count,), dtype=\"float32\")\n",
    "    fidelity_loss_on_kfold_mean_singleclassifier = \\\n",
    "        np.empty(shape=(len(models), test_instances_count,), dtype=\"float32\")\n",
    "    fidelity_loss_on_kfold_std_singleclassifier = \\\n",
    "        np.empty(shape=(len(models), test_instances_count,), dtype=\"float32\")\n",
    "    fidelity_loss_distribution_quantiles_singleclassifier = \\\n",
    "        np.empty(shape=(len(models), test_instances_count, bins_count), dtype=\"float32\")\n",
    "\n",
    "    for model_idx, (classifier_name, model) in enumerate(models):\n",
    "\n",
    "        explainer_multiregression = lime.lime_tabular_singleclassifier.LTESingleDecisionTree(\n",
    "            dataset.train_data.to_numpy(),\n",
    "            feature_names = dataset.train_data.columns.to_list(),\n",
    "            class_names = model.classes_,\n",
    "            discretize_continuous=False,\n",
    "            sample_around_instance=True,\n",
    "            categorical_features=dataset.categorical_features,\n",
    "            with_kfold=5\n",
    "        )\n",
    "\n",
    "        for instance_idx, test_instance in enumerate(tqdm(\n",
    "                    test_data_subset,\n",
    "                    desc=f\"{classifier_name}\",\n",
    "                    bar_format=\"{desc:<20}{percentage:3.0f}%|{bar}{r_bar}\"\n",
    "        )):\n",
    "\n",
    "            explanation = explainer_multiregression.explain_instance(\n",
    "                test_instance.reshape(-1),\n",
    "                model.predict_proba,\n",
    "                num_features = 4,\n",
    "                top_labels = labels_count,\n",
    "                distance_metric=\"minkowski\",\n",
    "                minkowski_norm=100.\n",
    "            )\n",
    "            scores_for_surrogate_model_singleclassifier[model_idx, instance_idx, :] = \\\n",
    "                explanation.get_scores_for_surrogate_model()\n",
    "            losses_for_surrogate_model_singleclassifier[model_idx, instance_idx, :] = \\\n",
    "                explanation.get_losses_for_surrogate_model()\n",
    "            losses_mean_for_cv_model_singleclassifier[model_idx, instance_idx, :] = \\\n",
    "                explanation.get_losses_for_cv_model(out=\"mean\")\n",
    "            losses_std_for_cv_model_singleclassifier[model_idx, instance_idx, :] = \\\n",
    "                explanation.get_losses_for_cv_model(out=\"std\")\n",
    "            fidelity_loss_on_explanation_singleclassifier[model_idx, instance_idx] = \\\n",
    "                explanation.get_fidelity_loss_on_explanation()\n",
    "            fidelity_loss_on_generated_data_singleclassifier[model_idx, instance_idx] = \\\n",
    "                explanation.get_fidelity_loss_on_generated_data()\n",
    "            fidelity_loss_on_kfold_mean_singleclassifier[model_idx, instance_idx] = \\\n",
    "                explanation.get_fidelity_loss_on_kfold(out=\"mean\")\n",
    "            fidelity_loss_on_kfold_std_singleclassifier[model_idx, instance_idx] = \\\n",
    "                explanation.get_fidelity_loss_on_kfold(out=\"std\")\n",
    "            fidelity_loss_distribution_quantiles_singleclassifier[model_idx, instance_idx, :] = \\\n",
    "                explanation.get_fidelity_loss_distribution(quantiles=bins_count)\n",
    "\n",
    "    postprocessor_singleclassifier = rp.ResultsProcessing(\n",
    "        models,\n",
    "        labels_count,\n",
    "        scores_for_surrogate_model_singleclassifier,\n",
    "        losses_for_surrogate_model_singleclassifier,\n",
    "        losses_mean_for_cv_model_singleclassifier,\n",
    "        losses_std_for_cv_model_singleclassifier,\n",
    "        fidelity_loss_on_explanation_singleclassifier,\n",
    "        fidelity_loss_on_generated_data_singleclassifier,\n",
    "        fidelity_loss_on_kfold_mean_singleclassifier,\n",
    "        fidelity_loss_on_kfold_std_singleclassifier,\n",
    "        fidelity_loss_distribution_quantiles_singleclassifier\n",
    "    )\n",
    "    postprocessor_singleclassifier.save_results(results_file_singleclassifier)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "postprocessor_singleclassifier.plot_scores_for_surrogate_model()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "postprocessor_singleclassifier.plot_losses_for_surrogate_model()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "postprocessor_singleclassifier.plot_fidelity_loss_on_explanation()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "postprocessor_singleclassifier.plot_fidelity_losses_on_generated_data()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "postprocessor_singleclassifier.plot_fidelity_loss_distribution(domain_unit=\"Quantiles\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}