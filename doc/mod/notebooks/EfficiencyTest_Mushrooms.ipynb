{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.ensemble\n",
    "import os.path\n",
    "import sklearn.neural_network\n",
    "import sklearn.svm\n",
    "import sklearn.naive_bayes\n",
    "import sklearn.tree\n",
    "import lime.lime_tabular_mod\n",
    "import lime.lime_tabular_multiregressor\n",
    "import lime.lime_tabular_multiclassifier\n",
    "import lime.lime_tabular_singleclassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import doc.mod.utils.DatasetRepository as dr\n",
    "import doc.mod.utils.ResultsProcessing as rp\n",
    "from tqdm import tqdm\n",
    "\n",
    "repo = dr.DatasetRepository(\"../data\")\n",
    "\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"mode.chained_assignment\", None)\n",
    "plt.style.use({\"figure.facecolor\": \"white\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# Dataset: Mushrooms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      cap-shape_bell  cap-shape_conical  cap-shape_convex  cap-shape_flat  \\\n5249               0                  0                 0               1   \n5781               0                  0                 1               0   \n7586               1                  0                 0               0   \n6181               0                  0                 0               1   \n7338               0                  0                 0               0   \n...              ...                ...               ...             ...   \n6150               0                  0                 1               0   \n5386               0                  0                 1               0   \n1357               0                  0                 0               1   \n2977               0                  0                 1               0   \n2411               0                  0                 0               1   \n\n      cap-shape_knobbed  cap-shape_sunken  cap-surface_fibrous  \\\n5249                  0                 0                    0   \n5781                  0                 0                    0   \n7586                  0                 0                    0   \n6181                  0                 0                    0   \n7338                  1                 0                    0   \n...                 ...               ...                  ...   \n6150                  0                 0                    0   \n5386                  0                 0                    0   \n1357                  0                 0                    1   \n2977                  0                 0                    1   \n2411                  0                 0                    1   \n\n      cap-surface_grooves  cap-surface_scaly  cap-surface_smooth  \\\n5249                    0                  1                   0   \n5781                    0                  0                   1   \n7586                    0                  0                   1   \n6181                    0                  0                   1   \n7338                    0                  1                   0   \n...                   ...                ...                 ...   \n6150                    0                  0                   1   \n5386                    0                  1                   0   \n1357                    0                  0                   0   \n2977                    0                  0                   0   \n2411                    0                  0                   0   \n\n      cap-color_brown  cap-color_buff  cap-color_cinnamon  cap-color_gray  \\\n5249                0               0                   0               0   \n5781                0               0                   0               0   \n7586                0               0                   0               1   \n6181                1               0                   0               0   \n7338                1               0                   0               0   \n...               ...             ...                 ...             ...   \n6150                1               0                   0               0   \n5386                1               0                   0               0   \n1357                0               0                   0               0   \n2977                0               0                   0               1   \n2411                1               0                   0               0   \n\n      cap-color_green  cap-color_pink  cap-color_purple  cap-color_red  \\\n5249                0               0                 0              0   \n5781                0               1                 0              0   \n7586                0               0                 0              0   \n6181                0               0                 0              0   \n7338                0               0                 0              0   \n...               ...             ...               ...            ...   \n6150                0               0                 0              0   \n5386                0               0                 0              0   \n1357                0               0                 0              0   \n2977                0               0                 0              0   \n2411                0               0                 0              0   \n\n      cap-color_white  cap-color_yellow  bruises_bruises  bruises_no  \\\n5249                0                 1                0           1   \n5781                0                 0                1           0   \n7586                0                 0                0           1   \n6181                0                 0                0           1   \n7338                0                 0                0           1   \n...               ...               ...              ...         ...   \n6150                0                 0                0           1   \n5386                0                 0                0           1   \n1357                1                 0                0           1   \n2977                0                 0                1           0   \n2411                0                 0                1           0   \n\n      odor_almond  odor_anise  odor_creosote  odor_fishy  odor_foul  \\\n5249            0           0              0           0          1   \n5781            0           0              0           0          0   \n7586            0           0              0           0          0   \n6181            0           0              0           0          0   \n7338            0           0              0           0          1   \n...           ...         ...            ...         ...        ...   \n6150            0           0              0           0          0   \n5386            0           0              0           0          0   \n1357            0           0              0           0          0   \n2977            0           0              0           0          0   \n2411            0           0              0           0          0   \n\n      odor_musty  odor_none  odor_pungent  odor_spicy  \\\n5249           0          0             0           0   \n5781           0          1             0           0   \n7586           0          1             0           0   \n6181           0          0             0           1   \n7338           0          0             0           0   \n...          ...        ...           ...         ...   \n6150           0          0             0           1   \n5386           0          1             0           0   \n1357           0          1             0           0   \n2977           0          1             0           0   \n2411           0          1             0           0   \n\n      gill-attachment_attached  gill-attachment_free  gill-spacing_close  \\\n5249                         0                     1                   1   \n5781                         0                     1                   1   \n7586                         0                     1                   0   \n6181                         0                     1                   1   \n7338                         0                     1                   1   \n...                        ...                   ...                 ...   \n6150                         0                     1                   1   \n5386                         0                     1                   0   \n1357                         0                     1                   0   \n2977                         0                     1                   1   \n2411                         0                     1                   1   \n\n      gill-spacing_crowded  gill-size_broad  gill-size_narrow  \\\n5249                     0                1                 0   \n5781                     0                1                 0   \n7586                     1                1                 0   \n6181                     0                0                 1   \n7338                     0                0                 1   \n...                    ...              ...               ...   \n6150                     0                0                 1   \n5386                     1                0                 1   \n1357                     1                1                 0   \n2977                     0                1                 0   \n2411                     0                1                 0   \n\n      gill-color_black  gill-color_brown  gill-color_buff  \\\n5249                 0                 0                0   \n5781                 0                 0                0   \n7586                 0                 0                0   \n6181                 0                 0                1   \n7338                 0                 0                1   \n...                ...               ...              ...   \n6150                 0                 0                1   \n5386                 0                 0                0   \n1357                 0                 0                0   \n2977                 0                 0                0   \n2411                 0                 0                0   \n\n      gill-color_chocolate  gill-color_gray  gill-color_green  \\\n5249                     0                1                 0   \n5781                     0                0                 0   \n7586                     0                0                 0   \n6181                     0                0                 0   \n7338                     0                0                 0   \n...                    ...              ...               ...   \n6150                     0                0                 0   \n5386                     0                0                 0   \n1357                     0                0                 0   \n2977                     0                0                 0   \n2411                     0                0                 0   \n\n      gill-color_orange  gill-color_pink  gill-color_purple  gill-color_red  \\\n5249                  0                0                  0               0   \n5781                  0                0                  0               1   \n7586                  0                0                  0               0   \n6181                  0                0                  0               0   \n7338                  0                0                  0               0   \n...                 ...              ...                ...             ...   \n6150                  0                0                  0               0   \n5386                  0                0                  0               0   \n1357                  0                1                  0               0   \n2977                  0                0                  0               0   \n2411                  0                1                  0               0   \n\n      gill-color_white  gill-color_yellow  stalk-shape_enlarging  \\\n5249                 0                  0                      1   \n5781                 0                  0                      1   \n7586                 1                  0                      1   \n6181                 0                  0                      0   \n7338                 0                  0                      0   \n...                ...                ...                    ...   \n6150                 0                  0                      0   \n5386                 1                  0                      1   \n1357                 0                  0                      0   \n2977                 1                  0                      0   \n2411                 0                  0                      0   \n\n      stalk-shape_tapering  stalk-root_bulbous  stalk-root_club  \\\n5249                     0                   1                0   \n5781                     0                   0                0   \n7586                     0                   0                0   \n6181                     1                   0                0   \n7338                     1                   0                0   \n...                    ...                 ...              ...   \n6150                     1                   0                0   \n5386                     0                   1                0   \n1357                     1                   0                0   \n2977                     1                   1                0   \n2411                     1                   1                0   \n\n      stalk-root_equal  stalk-root_rooted  stalk-root_unknown  \\\n5249                 0                  0                   0   \n5781                 0                  0                   1   \n7586                 0                  0                   1   \n6181                 0                  0                   1   \n7338                 0                  0                   1   \n...                ...                ...                 ...   \n6150                 0                  0                   1   \n5386                 0                  0                   0   \n1357                 1                  0                   0   \n2977                 0                  0                   0   \n2411                 0                  0                   0   \n\n      stalk-surface-above-ring_fibrous  stalk-surface-above-ring_scaly  \\\n5249                                 0                               0   \n5781                                 0                               0   \n7586                                 0                               0   \n6181                                 0                               0   \n7338                                 0                               0   \n...                                ...                             ...   \n6150                                 0                               0   \n5386                                 1                               0   \n1357                                 0                               0   \n2977                                 0                               0   \n2411                                 0                               0   \n\n      stalk-surface-above-ring_silky  stalk-surface-above-ring_smooth  \\\n5249                               1                                0   \n5781                               0                                1   \n7586                               1                                0   \n6181                               1                                0   \n7338                               0                                1   \n...                              ...                              ...   \n6150                               0                                1   \n5386                               0                                0   \n1357                               0                                1   \n2977                               0                                1   \n2411                               0                                1   \n\n      stalk-surface-below-ring_fibrous  stalk-surface-below-ring_scaly  \\\n5249                                 0                               0   \n5781                                 0                               0   \n7586                                 0                               0   \n6181                                 0                               0   \n7338                                 0                               0   \n...                                ...                             ...   \n6150                                 0                               0   \n5386                                 1                               0   \n1357                                 0                               0   \n2977                                 0                               0   \n2411                                 0                               0   \n\n      stalk-surface-below-ring_silky  stalk-surface-below-ring_smooth  \\\n5249                               1                                0   \n5781                               0                                1   \n7586                               0                                1   \n6181                               1                                0   \n7338                               1                                0   \n...                              ...                              ...   \n6150                               0                                1   \n5386                               0                                0   \n1357                               0                                1   \n2977                               0                                1   \n2411                               0                                1   \n\n      stalk-color-above-ring_brown  stalk-color-above-ring_buff  \\\n5249                             0                            0   \n5781                             0                            0   \n7586                             0                            0   \n6181                             0                            0   \n7338                             0                            0   \n...                            ...                          ...   \n6150                             0                            0   \n5386                             0                            0   \n1357                             0                            0   \n2977                             0                            0   \n2411                             0                            0   \n\n      stalk-color-above-ring_cinnamon  stalk-color-above-ring_gray  \\\n5249                                0                            0   \n5781                                0                            0   \n7586                                0                            0   \n6181                                0                            0   \n7338                                0                            0   \n...                               ...                          ...   \n6150                                0                            0   \n5386                                0                            0   \n1357                                0                            0   \n2977                                0                            1   \n2411                                0                            0   \n\n      stalk-color-above-ring_orange  stalk-color-above-ring_pink  \\\n5249                              0                            1   \n5781                              0                            0   \n7586                              0                            0   \n6181                              0                            1   \n7338                              0                            1   \n...                             ...                          ...   \n6150                              0                            1   \n5386                              0                            0   \n1357                              0                            0   \n2977                              0                            0   \n2411                              0                            0   \n\n      stalk-color-above-ring_red  stalk-color-above-ring_white  \\\n5249                           0                             0   \n5781                           1                             0   \n7586                           0                             1   \n6181                           0                             0   \n7338                           0                             0   \n...                          ...                           ...   \n6150                           0                             0   \n5386                           0                             1   \n1357                           0                             1   \n2977                           0                             0   \n2411                           0                             1   \n\n      stalk-color-above-ring_yellow  stalk-color-below-ring_brown  \\\n5249                              0                             0   \n5781                              0                             0   \n7586                              0                             0   \n6181                              0                             0   \n7338                              0                             0   \n...                             ...                           ...   \n6150                              0                             0   \n5386                              0                             1   \n1357                              0                             0   \n2977                              0                             0   \n2411                              0                             0   \n\n      stalk-color-below-ring_buff  stalk-color-below-ring_cinnamon  \\\n5249                            1                                0   \n5781                            0                                0   \n7586                            0                                0   \n6181                            0                                0   \n7338                            0                                0   \n...                           ...                              ...   \n6150                            0                                0   \n5386                            0                                0   \n1357                            0                                0   \n2977                            0                                0   \n2411                            0                                0   \n\n      stalk-color-below-ring_gray  stalk-color-below-ring_orange  \\\n5249                            0                              0   \n5781                            0                              0   \n7586                            0                              0   \n6181                            0                              0   \n7338                            0                              0   \n...                           ...                            ...   \n6150                            0                              0   \n5386                            0                              0   \n1357                            0                              0   \n2977                            0                              0   \n2411                            0                              0   \n\n      stalk-color-below-ring_pink  stalk-color-below-ring_red  \\\n5249                            0                           0   \n5781                            0                           0   \n7586                            0                           0   \n6181                            0                           0   \n7338                            1                           0   \n...                           ...                         ...   \n6150                            1                           0   \n5386                            0                           0   \n1357                            0                           0   \n2977                            1                           0   \n2411                            1                           0   \n\n      stalk-color-below-ring_white  stalk-color-below-ring_yellow  \\\n5249                             0                              0   \n5781                             1                              0   \n7586                             1                              0   \n6181                             1                              0   \n7338                             0                              0   \n...                            ...                            ...   \n6150                             0                              0   \n5386                             0                              0   \n1357                             1                              0   \n2977                             0                              0   \n2411                             0                              0   \n\n      veil-type_partial  veil-color_brown  veil-color_orange  \\\n5249                  1                 0                  0   \n5781                  1                 0                  0   \n7586                  1                 0                  0   \n6181                  1                 0                  0   \n7338                  1                 0                  0   \n...                 ...               ...                ...   \n6150                  1                 0                  0   \n5386                  1                 0                  0   \n1357                  1                 0                  0   \n2977                  1                 0                  0   \n2411                  1                 0                  0   \n\n      veil-color_white  veil-color_yellow  ring-number_none  ring-number_one  \\\n5249                 1                  0                 0                1   \n5781                 1                  0                 0                0   \n7586                 1                  0                 0                0   \n6181                 1                  0                 0                1   \n7338                 1                  0                 0                1   \n...                ...                ...               ...              ...   \n6150                 1                  0                 0                1   \n5386                 1                  0                 0                1   \n1357                 1                  0                 0                1   \n2977                 1                  0                 0                1   \n2411                 1                  0                 0                1   \n\n      ring-number_two  ring-type_evanescent  ring-type_flaring  \\\n5249                0                     0                  0   \n5781                1                     1                  0   \n7586                1                     0                  0   \n6181                0                     1                  0   \n7338                0                     1                  0   \n...               ...                   ...                ...   \n6150                0                     1                  0   \n5386                0                     1                  0   \n1357                0                     1                  0   \n2977                0                     0                  0   \n2411                0                     0                  0   \n\n      ring-type_large  ring-type_none  ring-type_pendant  \\\n5249                1               0                  0   \n5781                0               0                  0   \n7586                0               0                  1   \n6181                0               0                  0   \n7338                0               0                  0   \n...               ...             ...                ...   \n6150                0               0                  0   \n5386                0               0                  0   \n1357                0               0                  0   \n2977                0               0                  1   \n2411                0               0                  1   \n\n      spore-print-color_black  spore-print-color_brown  \\\n5249                        0                        0   \n5781                        0                        0   \n7586                        0                        0   \n6181                        0                        0   \n7338                        0                        0   \n...                       ...                      ...   \n6150                        0                        0   \n5386                        0                        0   \n1357                        1                        0   \n2977                        0                        1   \n2411                        0                        1   \n\n      spore-print-color_buff  spore-print-color_chocolate  \\\n5249                       0                            1   \n5781                       0                            0   \n7586                       0                            0   \n6181                       0                            0   \n7338                       0                            0   \n...                      ...                          ...   \n6150                       0                            0   \n5386                       0                            0   \n1357                       0                            0   \n2977                       0                            0   \n2411                       0                            0   \n\n      spore-print-color_green  spore-print-color_orange  \\\n5249                        0                         0   \n5781                        0                         0   \n7586                        0                         0   \n6181                        0                         0   \n7338                        0                         0   \n...                       ...                       ...   \n6150                        0                         0   \n5386                        0                         0   \n1357                        0                         0   \n2977                        0                         0   \n2411                        0                         0   \n\n      spore-print-color_purple  spore-print-color_white  \\\n5249                         0                        0   \n5781                         0                        1   \n7586                         0                        1   \n6181                         0                        1   \n7338                         0                        1   \n...                        ...                      ...   \n6150                         0                        1   \n5386                         0                        1   \n1357                         0                        0   \n2977                         0                        0   \n2411                         0                        0   \n\n      spore-print-color_yellow  population_abundant  population_clustered  \\\n5249                         0                    0                     0   \n5781                         0                    0                     1   \n7586                         0                    0                     0   \n6181                         0                    0                     0   \n7338                         0                    0                     0   \n...                        ...                  ...                   ...   \n6150                         0                    0                     0   \n5386                         0                    0                     0   \n1357                         0                    1                     0   \n2977                         0                    0                     0   \n2411                         0                    0                     0   \n\n      population_numerous  population_scattered  population_several  \\\n5249                    0                     0                   0   \n5781                    0                     0                   0   \n7586                    0                     1                   0   \n6181                    0                     0                   1   \n7338                    0                     0                   1   \n...                   ...                   ...                 ...   \n6150                    0                     0                   1   \n5386                    0                     0                   1   \n1357                    0                     0                   0   \n2977                    0                     0                   0   \n2411                    0                     0                   1   \n\n      population_solitary  habitat_grasses  habitat_leaves  habitat_meadows  \\\n5249                    1                1               0                0   \n5781                    0                0               0                0   \n7586                    0                1               0                0   \n6181                    0                0               0                0   \n7338                    0                0               0                0   \n...                   ...              ...             ...              ...   \n6150                    0                0               0                0   \n5386                    0                0               1                0   \n1357                    0                1               0                0   \n2977                    1                0               0                0   \n2411                    0                0               0                0   \n\n      habitat_paths  habitat_urban  habitat_waste  habitat_woods  \n5249              0              0              0              0  \n5781              0              0              1              0  \n7586              0              0              0              0  \n6181              0              0              0              1  \n7338              1              0              0              0  \n...             ...            ...            ...            ...  \n6150              0              0              0              1  \n5386              0              0              0              0  \n1357              0              0              0              0  \n2977              0              0              0              1  \n2411              0              0              0              1  \n\n[6499 rows x 117 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cap-shape_bell</th>\n      <th>cap-shape_conical</th>\n      <th>cap-shape_convex</th>\n      <th>cap-shape_flat</th>\n      <th>cap-shape_knobbed</th>\n      <th>cap-shape_sunken</th>\n      <th>cap-surface_fibrous</th>\n      <th>cap-surface_grooves</th>\n      <th>cap-surface_scaly</th>\n      <th>cap-surface_smooth</th>\n      <th>cap-color_brown</th>\n      <th>cap-color_buff</th>\n      <th>cap-color_cinnamon</th>\n      <th>cap-color_gray</th>\n      <th>cap-color_green</th>\n      <th>cap-color_pink</th>\n      <th>cap-color_purple</th>\n      <th>cap-color_red</th>\n      <th>cap-color_white</th>\n      <th>cap-color_yellow</th>\n      <th>bruises_bruises</th>\n      <th>bruises_no</th>\n      <th>odor_almond</th>\n      <th>odor_anise</th>\n      <th>odor_creosote</th>\n      <th>odor_fishy</th>\n      <th>odor_foul</th>\n      <th>odor_musty</th>\n      <th>odor_none</th>\n      <th>odor_pungent</th>\n      <th>odor_spicy</th>\n      <th>gill-attachment_attached</th>\n      <th>gill-attachment_free</th>\n      <th>gill-spacing_close</th>\n      <th>gill-spacing_crowded</th>\n      <th>gill-size_broad</th>\n      <th>gill-size_narrow</th>\n      <th>gill-color_black</th>\n      <th>gill-color_brown</th>\n      <th>gill-color_buff</th>\n      <th>gill-color_chocolate</th>\n      <th>gill-color_gray</th>\n      <th>gill-color_green</th>\n      <th>gill-color_orange</th>\n      <th>gill-color_pink</th>\n      <th>gill-color_purple</th>\n      <th>gill-color_red</th>\n      <th>gill-color_white</th>\n      <th>gill-color_yellow</th>\n      <th>stalk-shape_enlarging</th>\n      <th>stalk-shape_tapering</th>\n      <th>stalk-root_bulbous</th>\n      <th>stalk-root_club</th>\n      <th>stalk-root_equal</th>\n      <th>stalk-root_rooted</th>\n      <th>stalk-root_unknown</th>\n      <th>stalk-surface-above-ring_fibrous</th>\n      <th>stalk-surface-above-ring_scaly</th>\n      <th>stalk-surface-above-ring_silky</th>\n      <th>stalk-surface-above-ring_smooth</th>\n      <th>stalk-surface-below-ring_fibrous</th>\n      <th>stalk-surface-below-ring_scaly</th>\n      <th>stalk-surface-below-ring_silky</th>\n      <th>stalk-surface-below-ring_smooth</th>\n      <th>stalk-color-above-ring_brown</th>\n      <th>stalk-color-above-ring_buff</th>\n      <th>stalk-color-above-ring_cinnamon</th>\n      <th>stalk-color-above-ring_gray</th>\n      <th>stalk-color-above-ring_orange</th>\n      <th>stalk-color-above-ring_pink</th>\n      <th>stalk-color-above-ring_red</th>\n      <th>stalk-color-above-ring_white</th>\n      <th>stalk-color-above-ring_yellow</th>\n      <th>stalk-color-below-ring_brown</th>\n      <th>stalk-color-below-ring_buff</th>\n      <th>stalk-color-below-ring_cinnamon</th>\n      <th>stalk-color-below-ring_gray</th>\n      <th>stalk-color-below-ring_orange</th>\n      <th>stalk-color-below-ring_pink</th>\n      <th>stalk-color-below-ring_red</th>\n      <th>stalk-color-below-ring_white</th>\n      <th>stalk-color-below-ring_yellow</th>\n      <th>veil-type_partial</th>\n      <th>veil-color_brown</th>\n      <th>veil-color_orange</th>\n      <th>veil-color_white</th>\n      <th>veil-color_yellow</th>\n      <th>ring-number_none</th>\n      <th>ring-number_one</th>\n      <th>ring-number_two</th>\n      <th>ring-type_evanescent</th>\n      <th>ring-type_flaring</th>\n      <th>ring-type_large</th>\n      <th>ring-type_none</th>\n      <th>ring-type_pendant</th>\n      <th>spore-print-color_black</th>\n      <th>spore-print-color_brown</th>\n      <th>spore-print-color_buff</th>\n      <th>spore-print-color_chocolate</th>\n      <th>spore-print-color_green</th>\n      <th>spore-print-color_orange</th>\n      <th>spore-print-color_purple</th>\n      <th>spore-print-color_white</th>\n      <th>spore-print-color_yellow</th>\n      <th>population_abundant</th>\n      <th>population_clustered</th>\n      <th>population_numerous</th>\n      <th>population_scattered</th>\n      <th>population_several</th>\n      <th>population_solitary</th>\n      <th>habitat_grasses</th>\n      <th>habitat_leaves</th>\n      <th>habitat_meadows</th>\n      <th>habitat_paths</th>\n      <th>habitat_urban</th>\n      <th>habitat_waste</th>\n      <th>habitat_woods</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>5249</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5781</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7586</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6181</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7338</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>6150</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5386</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1357</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2977</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2411</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>6499 rows × 117 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_count = 2\n",
    "bins_count = 30\n",
    "version_str = \"v3\"\n",
    "dataset_name = \"Mushrooms\"\n",
    "dataset = repo.get_mushrooms_dataset(random_state=42)\n",
    "dataset.train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Train different classifiers on the selected dataset (with their default settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "models = [\n",
    "    (\"Random Forest\", sklearn.ensemble.RandomForestClassifier(n_jobs=-1)),\n",
    "    (\"AdaBoost\", sklearn.ensemble.AdaBoostClassifier()),\n",
    "    (\"DecisionTree\", sklearn.tree.DecisionTreeClassifier()),\n",
    "    (\"Neural Network\", sklearn.neural_network.MLPClassifier()),\n",
    "    # (\"SVM\", sklearn.svm.LinearSVC()), do not provide predict_proba\n",
    "    (\"Naive Bayes\", sklearn.naive_bayes.GaussianNB()),\n",
    "    (\"kNN\", sklearn.neighbors.KNeighborsClassifier())\n",
    "]\n",
    "precision_for_classifier = {}\n",
    "recall_for_classifier = {}\n",
    "f1_for_classifier = {}\n",
    "for (classifier_name, model) in models:\n",
    "    x = dataset.train_data.to_numpy()\n",
    "    y = dataset.train_labels.to_numpy()\n",
    "    model.fit(x, y)\n",
    "\n",
    "    x = dataset.test_data.to_numpy()\n",
    "    y_true = dataset.test_labels.to_numpy()\n",
    "    y_predicted = model.predict(x)\n",
    "\n",
    "    precision_for_classifier[classifier_name] = sklearn.metrics.precision_score(y_true=y_true, y_pred=y_predicted, average=\"macro\")\n",
    "    recall_for_classifier[classifier_name] = sklearn.metrics.recall_score(y_true=y_true, y_pred=y_predicted, average=\"macro\")\n",
    "    f1_for_classifier[classifier_name] = sklearn.metrics.f1_score(y_true=y_true, y_pred=y_predicted, average=\"macro\")\n",
    "\n",
    "test_data_subset = dataset.test_data.to_numpy()\n",
    "\n",
    "test_instances_count = test_data_subset.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "plt.figure(figsize=(14,4))\n",
    "plt.bar(f1_for_classifier.keys(), f1_for_classifier.values(), width=0.5)\n",
    "plt.title(\"f1_score\")\n",
    "plt.grid(axis=\"y\")\n",
    "plt.show()"
   ],
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1008x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "## Use original LIME to explain classifiers' predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Random Forest         1%|          | 11/1625 [01:38<4:01:49,  8.99s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-5-dd1e9125a4fa>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     51\u001B[0m                 \u001B[0mtop_labels\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlabels_count\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     52\u001B[0m                 \u001B[0mdistance_metric\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m\"minkowski\"\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 53\u001B[1;33m                 \u001B[0mminkowski_norm\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m100.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     54\u001B[0m             )\n\u001B[0;32m     55\u001B[0m             \u001B[0mscores_for_surrogate_model_default\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mmodel_idx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minstance_idx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m:\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m\\\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Documents\\MGR\\lime\\lime\\lime_tabular_mod.py\u001B[0m in \u001B[0;36mexplain_instance\u001B[1;34m(self, data_row, predict_fn, labels, top_labels, num_features, num_samples, distance_metric, model_regressor, sampling_method, minkowski_norm)\u001B[0m\n\u001B[0;32m    166\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    167\u001B[0m         new_explanation = self._create_explanation(\n\u001B[1;32m--> 168\u001B[1;33m             \u001B[0mdistances\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdomain_mapper\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlabels\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmodel_regressor\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnum_features\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mscaled_data\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtop_labels\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0myss\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    169\u001B[0m         )\n\u001B[0;32m    170\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Documents\\MGR\\lime\\lime\\lime_tabular_mod.py\u001B[0m in \u001B[0;36m_create_explanation\u001B[1;34m(self, distances, domain_mapper, labels, model_regressor, num_features, scaled_data, top_labels, yss)\u001B[0m\n\u001B[0;32m    286\u001B[0m                     \u001B[0myss\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    287\u001B[0m                     \u001B[0mlabels_column\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 288\u001B[1;33m                     kf)\n\u001B[0m\u001B[0;32m    289\u001B[0m                 \u001B[0mnew_explanation\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcv_evaluation_results\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mlabel_idx\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcv_evaluation_results\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    290\u001B[0m                 \u001B[0mcv_subexplainers_for_label_idx\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mlabel_idx\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcv_subexplainers\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Documents\\MGR\\lime\\lime\\lime_tabular_mod.py\u001B[0m in \u001B[0;36m_cross_validate_subexplainer\u001B[1;34m(self, distances, label_idx, model_regressor, num_features, scaled_data, yss, labels_column, kf)\u001B[0m\n\u001B[0;32m    361\u001B[0m                     \u001B[0mnum_features\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    362\u001B[0m                     \u001B[0mmodel_regressor\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mmodel_regressor\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 363\u001B[1;33m                     feature_selection=self.feature_selection)\n\u001B[0m\u001B[0;32m    364\u001B[0m             \u001B[0mrow_x_indices\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mreshape\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtest_indices\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m(\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    365\u001B[0m             \u001B[0mcolumn_x_indices\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrepeat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mreshape\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mused_features\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m(\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtest_indices\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Documents\\MGR\\lime\\lime\\lime_base_mod.py\u001B[0m in \u001B[0;36mexplain_instance_with_data\u001B[1;34m(self, neighborhood_data, neighborhood_labels, distances, label, num_features, feature_selection, model_regressor)\u001B[0m\n\u001B[0;32m     83\u001B[0m                 \u001B[0mneighborhood_data\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     84\u001B[0m                 \u001B[0mneighborhood_labels\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 85\u001B[1;33m                 num_features)\n\u001B[0m\u001B[0;32m     86\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     87\u001B[0m         \u001B[0mexplanation\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_get_explanation\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlocal_surrogate\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mused_features\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Documents\\MGR\\lime\\lime\\lime_base_mod.py\u001B[0m in \u001B[0;36m_train_local_surrogate\u001B[1;34m(self, distances, feature_selection, label, model_regressor, neighborhood_data, neighborhood_labels, num_features)\u001B[0m\n\u001B[0;32m    110\u001B[0m             \u001B[0mweights\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    111\u001B[0m             \u001B[0mnum_features\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 112\u001B[1;33m             feature_selection)\n\u001B[0m\u001B[0;32m    113\u001B[0m         \u001B[0mdata_to_train_local_surrogate\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mneighborhood_data\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mused_features\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    114\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mmodel_regressor\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Documents\\MGR\\lime\\lime\\lime_base.py\u001B[0m in \u001B[0;36mfeature_selection\u001B[1;34m(self, data, labels, weights, num_features, method)\u001B[0m\n\u001B[0;32m    141\u001B[0m                 \u001B[0mn_method\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;34m'highest_weights'\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    142\u001B[0m             return self.feature_selection(data, labels, weights,\n\u001B[1;32m--> 143\u001B[1;33m                                           num_features, n_method)\n\u001B[0m\u001B[0;32m    144\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    145\u001B[0m     def explain_instance_with_data(self,\n",
      "\u001B[1;32m~\\Documents\\MGR\\lime\\lime\\lime_base.py\u001B[0m in \u001B[0;36mfeature_selection\u001B[1;34m(self, data, labels, weights, num_features, method)\u001B[0m\n\u001B[0;32m     82\u001B[0m             \u001B[1;32mreturn\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0marray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mrange\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     83\u001B[0m         \u001B[1;32melif\u001B[0m \u001B[0mmethod\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;34m'forward_selection'\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 84\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mforward_selection\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlabels\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mweights\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnum_features\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     85\u001B[0m         \u001B[1;32melif\u001B[0m \u001B[0mmethod\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;34m'highest_weights'\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     86\u001B[0m             clf = Ridge(alpha=0.01, fit_intercept=True,\n",
      "\u001B[1;32m~\\Documents\\MGR\\lime\\lime\\lime_base.py\u001B[0m in \u001B[0;36mforward_selection\u001B[1;34m(self, data, labels, weights, num_features)\u001B[0m\n\u001B[0;32m     66\u001B[0m                     \u001B[1;32mcontinue\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     67\u001B[0m                 clf.fit(data[:, used_features + [feature]], labels,\n\u001B[1;32m---> 68\u001B[1;33m                         sample_weight=weights)\n\u001B[0m\u001B[0;32m     69\u001B[0m                 score = clf.score(data[:, used_features + [feature]],\n\u001B[0;32m     70\u001B[0m                                   \u001B[0mlabels\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\kamil zych\\documents\\mgr\\lime\\venv\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[0;32m    760\u001B[0m         \u001B[0mself\u001B[0m \u001B[1;33m:\u001B[0m \u001B[0mreturns\u001B[0m \u001B[0man\u001B[0m \u001B[0minstance\u001B[0m \u001B[0mof\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    761\u001B[0m         \"\"\"\n\u001B[1;32m--> 762\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0msuper\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msample_weight\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0msample_weight\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    763\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    764\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\kamil zych\\documents\\mgr\\lime\\venv\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[0;32m    572\u001B[0m         X, y, X_offset, y_offset, X_scale = self._preprocess_data(\n\u001B[0;32m    573\u001B[0m             \u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit_intercept\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnormalize\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcopy_X\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 574\u001B[1;33m             sample_weight=sample_weight, return_mean=True)\n\u001B[0m\u001B[0;32m    575\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    576\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0msolver\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;34m'sag'\u001B[0m \u001B[1;32mand\u001B[0m \u001B[0msparse\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0missparse\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mand\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit_intercept\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\kamil zych\\documents\\mgr\\lime\\venv\\lib\\site-packages\\sklearn\\linear_model\\_base.py\u001B[0m in \u001B[0;36m_preprocess_data\u001B[1;34m(X, y, fit_intercept, normalize, copy, sample_weight, return_mean, check_input)\u001B[0m\n\u001B[0;32m    127\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mcheck_input\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    128\u001B[0m         X = check_array(X, copy=copy, accept_sparse=['csr', 'csc'],\n\u001B[1;32m--> 129\u001B[1;33m                         dtype=FLOAT_DTYPES)\n\u001B[0m\u001B[0;32m    130\u001B[0m     \u001B[1;32melif\u001B[0m \u001B[0mcopy\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    131\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0msp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0missparse\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\kamil zych\\documents\\mgr\\lime\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\u001B[0m in \u001B[0;36minner_f\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     70\u001B[0m                           FutureWarning)\n\u001B[0;32m     71\u001B[0m         \u001B[0mkwargs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m{\u001B[0m\u001B[0mk\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0marg\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mk\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0marg\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mzip\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msig\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mparameters\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0margs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m}\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 72\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mf\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     73\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0minner_f\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     74\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\kamil zych\\documents\\mgr\\lime\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\u001B[0m in \u001B[0;36mcheck_array\u001B[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001B[0m\n\u001B[0;32m    643\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mforce_all_finite\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    644\u001B[0m             _assert_all_finite(array,\n\u001B[1;32m--> 645\u001B[1;33m                                allow_nan=force_all_finite == 'allow-nan')\n\u001B[0m\u001B[0;32m    646\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    647\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mensure_min_samples\u001B[0m \u001B[1;33m>\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\kamil zych\\documents\\mgr\\lime\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\u001B[0m in \u001B[0;36m_assert_all_finite\u001B[1;34m(X, allow_nan, msg_dtype)\u001B[0m\n\u001B[0;32m     87\u001B[0m     \u001B[1;31m# safely to reduce dtype induced overflows.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     88\u001B[0m     \u001B[0mis_float\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mX\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mkind\u001B[0m \u001B[1;32min\u001B[0m \u001B[1;34m'fc'\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 89\u001B[1;33m     \u001B[1;32mif\u001B[0m \u001B[0mis_float\u001B[0m \u001B[1;32mand\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0misfinite\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0m_safe_accumulator_op\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msum\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mX\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     90\u001B[0m         \u001B[1;32mpass\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     91\u001B[0m     \u001B[1;32melif\u001B[0m \u001B[0mis_float\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\kamil zych\\documents\\mgr\\lime\\venv\\lib\\site-packages\\sklearn\\utils\\extmath.py\u001B[0m in \u001B[0;36m_safe_accumulator_op\u001B[1;34m(op, x, *args, **kwargs)\u001B[0m\n\u001B[0;32m    709\u001B[0m         \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mop\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfloat64\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    710\u001B[0m     \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 711\u001B[1;33m         \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mop\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    712\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mresult\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    713\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<__array_function__ internals>\u001B[0m in \u001B[0;36msum\u001B[1;34m(*args, **kwargs)\u001B[0m\n",
      "\u001B[1;32mc:\\users\\kamil zych\\documents\\mgr\\lime\\venv\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001B[0m in \u001B[0;36msum\u001B[1;34m(a, axis, dtype, out, keepdims, initial, where)\u001B[0m\n\u001B[0;32m   2240\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2241\u001B[0m     return _wrapreduction(a, np.add, 'sum', axis, dtype, out, keepdims=keepdims,\n\u001B[1;32m-> 2242\u001B[1;33m                           initial=initial, where=where)\n\u001B[0m\u001B[0;32m   2243\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2244\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\kamil zych\\documents\\mgr\\lime\\venv\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001B[0m in \u001B[0;36m_wrapreduction\u001B[1;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001B[0m\n\u001B[0;32m     85\u001B[0m                 \u001B[1;32mreturn\u001B[0m \u001B[0mreduction\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0maxis\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0maxis\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mout\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mout\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mpasskwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     86\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 87\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0mufunc\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mreduce\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mobj\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mout\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mpasskwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     88\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     89\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "results_file_default = f\"saved_results/{dataset_name}/default_results_{version_str}\"\n",
    "if os.path.isfile(results_file_default + \".npy\"):\n",
    "    postprocessor_default = rp.ResultsProcessing.from_file(\n",
    "        results_file_default,\n",
    "        models,\n",
    "        labels_count\n",
    "    )\n",
    "\n",
    "else:\n",
    "    scores_for_surrogate_model_default = \\\n",
    "        np.empty(shape=(len(models), test_instances_count, labels_count), dtype=\"float32\")\n",
    "    losses_for_surrogate_model_default = \\\n",
    "        np.empty(shape=(len(models), test_instances_count, labels_count), dtype=\"float32\")\n",
    "    losses_mean_for_cv_model_default = \\\n",
    "        np.empty(shape=(len(models), test_instances_count, labels_count), dtype=\"float32\")\n",
    "    losses_std_for_cv_model_default = \\\n",
    "        np.empty(shape=(len(models), test_instances_count, labels_count), dtype=\"float32\")\n",
    "    fidelity_loss_on_explanation_default = \\\n",
    "        np.empty(shape=(len(models), test_instances_count,), dtype=\"float32\")\n",
    "    fidelity_loss_on_generated_data_default = \\\n",
    "        np.empty(shape=(len(models), test_instances_count,), dtype=\"float32\")\n",
    "    fidelity_loss_on_kfold_mean_default = \\\n",
    "        np.empty(shape=(len(models), test_instances_count,), dtype=\"float32\")\n",
    "    fidelity_loss_on_kfold_std_default = \\\n",
    "        np.empty(shape=(len(models), test_instances_count,), dtype=\"float32\")\n",
    "    fidelity_loss_distribution_quantiles_default = \\\n",
    "        np.empty(shape=(len(models), test_instances_count, bins_count), dtype=\"float32\")\n",
    "\n",
    "    for model_idx, (classifier_name, model) in enumerate(models):\n",
    "\n",
    "        explainer_default = lime.lime_tabular_mod.LimeTabularExplainerMod(\n",
    "            dataset.train_data.to_numpy(),\n",
    "            feature_names = dataset.train_data.columns.to_list(),\n",
    "            class_names = model.classes_,\n",
    "            discretize_continuous=False,\n",
    "            sample_around_instance=True,\n",
    "            categorical_features=dataset.categorical_features,\n",
    "            with_kfold=5\n",
    "        )\n",
    "\n",
    "        for instance_idx, test_instance in enumerate(tqdm(\n",
    "                    test_data_subset,\n",
    "                    desc=f\"{classifier_name}\",\n",
    "                    bar_format=\"{desc:<20}{percentage:3.0f}%|{bar}{r_bar}\"\n",
    "        )):\n",
    "\n",
    "            explanation = explainer_default.explain_instance(\n",
    "                test_instance.reshape(-1),\n",
    "                model.predict_proba,\n",
    "                num_features = 4,\n",
    "                top_labels = labels_count,\n",
    "                distance_metric=\"minkowski\",\n",
    "                minkowski_norm=100.\n",
    "            )\n",
    "            scores_for_surrogate_model_default[model_idx, instance_idx, :] = \\\n",
    "                explanation.get_scores_for_surrogate_model()\n",
    "            losses_for_surrogate_model_default[model_idx, instance_idx, :] = \\\n",
    "                explanation.get_losses_for_surrogate_model()\n",
    "            losses_mean_for_cv_model_default[model_idx, instance_idx, :] = \\\n",
    "                explanation.get_losses_for_cv_model(out=\"mean\")\n",
    "            losses_std_for_cv_model_default[model_idx, instance_idx, :] = \\\n",
    "                explanation.get_losses_for_cv_model(out=\"std\")\n",
    "            fidelity_loss_on_explanation_default[model_idx, instance_idx] = \\\n",
    "                explanation.get_fidelity_loss_on_explanation()\n",
    "            fidelity_loss_on_generated_data_default[model_idx, instance_idx] = \\\n",
    "                explanation.get_fidelity_loss_on_generated_data()\n",
    "            fidelity_loss_on_kfold_mean_default[model_idx, instance_idx] = \\\n",
    "                explanation.get_fidelity_loss_on_kfold(out=\"mean\")\n",
    "            fidelity_loss_on_kfold_std_default[model_idx, instance_idx] = \\\n",
    "                explanation.get_fidelity_loss_on_kfold(out=\"std\")\n",
    "            fidelity_loss_distribution_quantiles_default[model_idx, instance_idx, :] = \\\n",
    "                explanation.get_fidelity_loss_distribution(quantiles=bins_count)\n",
    "\n",
    "    postprocessor_default = rp.ResultsProcessing(\n",
    "        models,\n",
    "        labels_count,\n",
    "        scores_for_surrogate_model_default,\n",
    "        losses_for_surrogate_model_default,\n",
    "        losses_mean_for_cv_model_default,\n",
    "        losses_std_for_cv_model_default,\n",
    "        fidelity_loss_on_explanation_default,\n",
    "        fidelity_loss_on_generated_data_default,\n",
    "        fidelity_loss_on_kfold_mean_default,\n",
    "        fidelity_loss_on_kfold_std_default,\n",
    "        fidelity_loss_distribution_quantiles_default\n",
    "    )\n",
    "    postprocessor_default.save_results(results_file_default)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "postprocessor_default.plot_scores_for_surrogate_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "postprocessor_default.plot_losses_for_surrogate_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "postprocessor_default.plot_fidelity_loss_on_explanation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "postprocessor_default.plot_fidelity_losses_on_generated_data()"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "postprocessor_default.plot_fidelity_loss_distribution(domain_unit=\"Quantiles\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "## Use modified LIME to explain classifiers' predictions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "### Use multiple Regression Trees as local surrogate"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results_file_multiregression = f\"saved_results/{dataset_name}/multiregression_results_{version_str}\"\n",
    "if os.path.isfile(results_file_multiregression + \".npy\"):\n",
    "    postprocessor_multiregression = rp.ResultsProcessing.from_file(\n",
    "        results_file_multiregression,\n",
    "        models,\n",
    "        labels_count\n",
    "    )\n",
    "\n",
    "else:\n",
    "    scores_for_surrogate_model_multiregression = \\\n",
    "        np.empty(shape=(len(models), test_instances_count, labels_count), dtype=\"float32\")\n",
    "    losses_for_surrogate_model_multiregression = \\\n",
    "        np.empty(shape=(len(models), test_instances_count, labels_count), dtype=\"float32\")\n",
    "    losses_mean_for_cv_model_multiregression = \\\n",
    "        np.empty(shape=(len(models), test_instances_count, labels_count), dtype=\"float32\")\n",
    "    losses_std_for_cv_model_multiregression = \\\n",
    "        np.empty(shape=(len(models), test_instances_count, labels_count), dtype=\"float32\")\n",
    "    fidelity_loss_on_explanation_multiregression = \\\n",
    "        np.empty(shape=(len(models), test_instances_count,), dtype=\"float32\")\n",
    "    fidelity_loss_on_generated_data_multiregression = \\\n",
    "        np.empty(shape=(len(models), test_instances_count,), dtype=\"float32\")\n",
    "    fidelity_loss_on_kfold_mean_multiregression = \\\n",
    "        np.empty(shape=(len(models), test_instances_count,), dtype=\"float32\")\n",
    "    fidelity_loss_on_kfold_std_multiregression = \\\n",
    "        np.empty(shape=(len(models), test_instances_count,), dtype=\"float32\")\n",
    "    fidelity_loss_distribution_quantiles_multiregression = \\\n",
    "        np.empty(shape=(len(models), test_instances_count, bins_count), dtype=\"float32\")\n",
    "\n",
    "    for model_idx, (classifier_name, model) in enumerate(models):\n",
    "\n",
    "        explainer_multiregression = lime.lime_tabular_multiregressor.LTEMultiRegressionTree(\n",
    "            dataset.train_data.to_numpy(),\n",
    "            feature_names = dataset.train_data.columns.to_list(),\n",
    "            class_names = model.classes_,\n",
    "            discretize_continuous=False,\n",
    "            sample_around_instance=True,\n",
    "            categorical_features=dataset.categorical_features,\n",
    "            with_kfold=5\n",
    "        )\n",
    "\n",
    "        for instance_idx, test_instance in enumerate(tqdm(\n",
    "                    test_data_subset,\n",
    "                    desc=f\"{classifier_name}\",\n",
    "                    bar_format=\"{desc:<20}{percentage:3.0f}%|{bar}{r_bar}\"\n",
    "        )):\n",
    "\n",
    "            explanation = explainer_multiregression.explain_instance(\n",
    "                test_instance.reshape(-1),\n",
    "                model.predict_proba,\n",
    "                num_features = 4,\n",
    "                top_labels = labels_count,\n",
    "                distance_metric=\"minkowski\",\n",
    "                minkowski_norm=100.\n",
    "            )\n",
    "            scores_for_surrogate_model_multiregression[model_idx, instance_idx, :] = \\\n",
    "                explanation.get_scores_for_surrogate_model()\n",
    "            losses_for_surrogate_model_multiregression[model_idx, instance_idx, :] = \\\n",
    "                explanation.get_losses_for_surrogate_model()\n",
    "            losses_mean_for_cv_model_multiregression[model_idx, instance_idx, :] = \\\n",
    "                explanation.get_losses_for_cv_model(out=\"mean\")\n",
    "            losses_std_for_cv_model_multiregression[model_idx, instance_idx, :] = \\\n",
    "                explanation.get_losses_for_cv_model(out=\"std\")\n",
    "            fidelity_loss_on_explanation_multiregression[model_idx, instance_idx] = \\\n",
    "                explanation.get_fidelity_loss_on_explanation()\n",
    "            fidelity_loss_on_generated_data_multiregression[model_idx, instance_idx] = \\\n",
    "                explanation.get_fidelity_loss_on_generated_data()\n",
    "            fidelity_loss_on_kfold_mean_multiregression[model_idx, instance_idx] = \\\n",
    "                explanation.get_fidelity_loss_on_kfold(out=\"mean\")\n",
    "            fidelity_loss_on_kfold_std_multiregression[model_idx, instance_idx] = \\\n",
    "                explanation.get_fidelity_loss_on_kfold(out=\"std\")\n",
    "            fidelity_loss_distribution_quantiles_multiregression[model_idx, instance_idx, :] = \\\n",
    "                explanation.get_fidelity_loss_distribution(quantiles=bins_count)\n",
    "\n",
    "    postprocessor_multiregression = rp.ResultsProcessing(\n",
    "        models,\n",
    "        labels_count,\n",
    "        scores_for_surrogate_model_multiregression,\n",
    "        losses_for_surrogate_model_multiregression,\n",
    "        losses_mean_for_cv_model_multiregression,\n",
    "        losses_std_for_cv_model_multiregression,\n",
    "        fidelity_loss_on_explanation_multiregression,\n",
    "        fidelity_loss_on_generated_data_multiregression,\n",
    "        fidelity_loss_on_kfold_mean_multiregression,\n",
    "        fidelity_loss_on_kfold_std_multiregression,\n",
    "        fidelity_loss_distribution_quantiles_multiregression\n",
    "    )\n",
    "    postprocessor_multiregression.save_results(results_file_multiregression)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "postprocessor_multiregression.plot_scores_for_surrogate_model()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "postprocessor_multiregression.plot_losses_for_surrogate_model()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "postprocessor_multiregression.plot_fidelity_loss_on_explanation()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "postprocessor_multiregression.plot_fidelity_losses_on_generated_data()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "postprocessor_multiregression.plot_fidelity_loss_distribution(domain_unit=\"Quantiles\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "### Use multiple Decision Trees as local surrogate"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results_file_multiclassifier = f\"saved_results/{dataset_name}/multiclassifier_results_{version_str}\"\n",
    "if os.path.isfile(results_file_multiclassifier + \".npy\"):\n",
    "    postprocessor_multiclassifier = rp.ResultsProcessing.from_file(\n",
    "        results_file_multiclassifier,\n",
    "        models,\n",
    "        labels_count\n",
    "    )\n",
    "\n",
    "else:\n",
    "    scores_for_surrogate_model_multiclassifier = \\\n",
    "        np.empty(shape=(len(models), test_instances_count, labels_count), dtype=\"float32\")\n",
    "    losses_for_surrogate_model_multiclassifier = \\\n",
    "        np.empty(shape=(len(models), test_instances_count, labels_count), dtype=\"float32\")\n",
    "    losses_mean_for_cv_model_multiclassifier = \\\n",
    "        np.empty(shape=(len(models), test_instances_count, labels_count), dtype=\"float32\")\n",
    "    losses_std_for_cv_model_multiclassifier = \\\n",
    "        np.empty(shape=(len(models), test_instances_count, labels_count), dtype=\"float32\")\n",
    "    fidelity_loss_on_explanation_multiclassifier = \\\n",
    "        np.empty(shape=(len(models), test_instances_count,), dtype=\"float32\")\n",
    "    fidelity_loss_on_generated_data_multiclassifier = \\\n",
    "        np.empty(shape=(len(models), test_instances_count,), dtype=\"float32\")\n",
    "    fidelity_loss_on_kfold_mean_multiclassifier = \\\n",
    "        np.empty(shape=(len(models), test_instances_count,), dtype=\"float32\")\n",
    "    fidelity_loss_on_kfold_std_multiclassifier = \\\n",
    "        np.empty(shape=(len(models), test_instances_count,), dtype=\"float32\")\n",
    "    fidelity_loss_distribution_quantiles_multiclassifier = \\\n",
    "        np.empty(shape=(len(models), test_instances_count, bins_count), dtype=\"float32\")\n",
    "\n",
    "    for model_idx, (classifier_name, model) in enumerate(models):\n",
    "\n",
    "        explainer_multiregression = lime.lime_tabular_multiclassifier.LTEMultiDecisionTree(\n",
    "            dataset.train_data.to_numpy(),\n",
    "            feature_names = dataset.train_data.columns.to_list(),\n",
    "            class_names = model.classes_,\n",
    "            discretize_continuous=False,\n",
    "            sample_around_instance=True,\n",
    "            categorical_features=dataset.categorical_features,\n",
    "            with_kfold=5\n",
    "        )\n",
    "\n",
    "        for instance_idx, test_instance in enumerate(tqdm(\n",
    "                    test_data_subset,\n",
    "                    desc=f\"{classifier_name}\",\n",
    "                    bar_format=\"{desc:<20}{percentage:3.0f}%|{bar}{r_bar}\"\n",
    "        )):\n",
    "\n",
    "            explanation = explainer_multiregression.explain_instance(\n",
    "                test_instance.reshape(-1),\n",
    "                model.predict_proba,\n",
    "                num_features = 4,\n",
    "                top_labels = labels_count,\n",
    "                distance_metric=\"minkowski\",\n",
    "                minkowski_norm=100.\n",
    "            )\n",
    "            scores_for_surrogate_model_multiclassifier[model_idx, instance_idx, :] = \\\n",
    "                explanation.get_scores_for_surrogate_model()\n",
    "            losses_for_surrogate_model_multiclassifier[model_idx, instance_idx, :] = \\\n",
    "                explanation.get_losses_for_surrogate_model()\n",
    "            losses_mean_for_cv_model_multiclassifier[model_idx, instance_idx, :] = \\\n",
    "                explanation.get_losses_for_cv_model(out=\"mean\")\n",
    "            losses_std_for_cv_model_multiclassifier[model_idx, instance_idx, :] = \\\n",
    "                explanation.get_losses_for_cv_model(out=\"std\")\n",
    "            fidelity_loss_on_explanation_multiclassifier[model_idx, instance_idx] = \\\n",
    "                explanation.get_fidelity_loss_on_explanation()\n",
    "            fidelity_loss_on_generated_data_multiclassifier[model_idx, instance_idx] = \\\n",
    "                explanation.get_fidelity_loss_on_generated_data()\n",
    "            fidelity_loss_on_kfold_mean_multiclassifier[model_idx, instance_idx] = \\\n",
    "                explanation.get_fidelity_loss_on_kfold(out=\"mean\")\n",
    "            fidelity_loss_on_kfold_std_multiclassifier[model_idx, instance_idx] = \\\n",
    "                explanation.get_fidelity_loss_on_kfold(out=\"std\")\n",
    "            fidelity_loss_distribution_quantiles_multiclassifier[model_idx, instance_idx, :] = \\\n",
    "                explanation.get_fidelity_loss_distribution(quantiles=bins_count)\n",
    "\n",
    "    postprocessor_multiclassifier = rp.ResultsProcessing(\n",
    "        models,\n",
    "        labels_count,\n",
    "        scores_for_surrogate_model_multiclassifier,\n",
    "        losses_for_surrogate_model_multiclassifier,\n",
    "        losses_mean_for_cv_model_multiclassifier,\n",
    "        losses_std_for_cv_model_multiclassifier,\n",
    "        fidelity_loss_on_explanation_multiclassifier,\n",
    "        fidelity_loss_on_generated_data_multiclassifier,\n",
    "        fidelity_loss_on_kfold_mean_multiclassifier,\n",
    "        fidelity_loss_on_kfold_std_multiclassifier,\n",
    "        fidelity_loss_distribution_quantiles_multiclassifier\n",
    "    )\n",
    "    postprocessor_multiclassifier.save_results(results_file_multiclassifier)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "postprocessor_multiclassifier.plot_scores_for_surrogate_model()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "postprocessor_multiclassifier.plot_losses_for_surrogate_model()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "postprocessor_multiclassifier.plot_fidelity_loss_on_explanation()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "postprocessor_multiclassifier.plot_fidelity_losses_on_generated_data()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "postprocessor_multiclassifier.plot_fidelity_loss_distribution(domain_unit=\"Quantiles\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "### Use single Decision Tree as local surrogate"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results_file_singleclassifier = f\"saved_results/{dataset_name}/singleclassifier_results_{version_str}\"\n",
    "if os.path.isfile(results_file_singleclassifier + \".npy\"):\n",
    "    postprocessor_singleclassifier = rp.ResultsProcessing.from_file(\n",
    "        results_file_singleclassifier,\n",
    "        models,\n",
    "        labels_count\n",
    "    )\n",
    "\n",
    "else:\n",
    "    scores_for_surrogate_model_singleclassifier = \\\n",
    "        np.empty(shape=(len(models), test_instances_count, labels_count), dtype=\"float32\")\n",
    "    losses_for_surrogate_model_singleclassifier = \\\n",
    "        np.empty(shape=(len(models), test_instances_count, labels_count), dtype=\"float32\")\n",
    "    losses_mean_for_cv_model_singleclassifier = \\\n",
    "        np.empty(shape=(len(models), test_instances_count, labels_count), dtype=\"float32\")\n",
    "    losses_std_for_cv_model_singleclassifier = \\\n",
    "        np.empty(shape=(len(models), test_instances_count, labels_count), dtype=\"float32\")\n",
    "    fidelity_loss_on_explanation_singleclassifier = \\\n",
    "        np.empty(shape=(len(models), test_instances_count,), dtype=\"float32\")\n",
    "    fidelity_loss_on_generated_data_singleclassifier = \\\n",
    "        np.empty(shape=(len(models), test_instances_count,), dtype=\"float32\")\n",
    "    fidelity_loss_on_kfold_mean_singleclassifier = \\\n",
    "        np.empty(shape=(len(models), test_instances_count,), dtype=\"float32\")\n",
    "    fidelity_loss_on_kfold_std_singleclassifier = \\\n",
    "        np.empty(shape=(len(models), test_instances_count,), dtype=\"float32\")\n",
    "    fidelity_loss_distribution_quantiles_singleclassifier = \\\n",
    "        np.empty(shape=(len(models), test_instances_count, bins_count), dtype=\"float32\")\n",
    "\n",
    "    for model_idx, (classifier_name, model) in enumerate(models):\n",
    "\n",
    "        explainer_multiregression = lime.lime_tabular_singleclassifier.LTESingleDecisionTree(\n",
    "            dataset.train_data.to_numpy(),\n",
    "            feature_names = dataset.train_data.columns.to_list(),\n",
    "            class_names = model.classes_,\n",
    "            discretize_continuous=False,\n",
    "            sample_around_instance=True,\n",
    "            categorical_features=dataset.categorical_features,\n",
    "            with_kfold=5\n",
    "        )\n",
    "\n",
    "        for instance_idx, test_instance in enumerate(tqdm(\n",
    "                    test_data_subset,\n",
    "                    desc=f\"{classifier_name}\",\n",
    "                    bar_format=\"{desc:<20}{percentage:3.0f}%|{bar}{r_bar}\"\n",
    "        )):\n",
    "\n",
    "            explanation = explainer_multiregression.explain_instance(\n",
    "                test_instance.reshape(-1),\n",
    "                model.predict_proba,\n",
    "                num_features = 4,\n",
    "                top_labels = labels_count,\n",
    "                distance_metric=\"minkowski\",\n",
    "                minkowski_norm=100.\n",
    "            )\n",
    "            scores_for_surrogate_model_singleclassifier[model_idx, instance_idx, :] = \\\n",
    "                explanation.get_scores_for_surrogate_model()\n",
    "            losses_for_surrogate_model_singleclassifier[model_idx, instance_idx, :] = \\\n",
    "                explanation.get_losses_for_surrogate_model()\n",
    "            losses_mean_for_cv_model_singleclassifier[model_idx, instance_idx, :] = \\\n",
    "                explanation.get_losses_for_cv_model(out=\"mean\")\n",
    "            losses_std_for_cv_model_singleclassifier[model_idx, instance_idx, :] = \\\n",
    "                explanation.get_losses_for_cv_model(out=\"std\")\n",
    "            fidelity_loss_on_explanation_singleclassifier[model_idx, instance_idx] = \\\n",
    "                explanation.get_fidelity_loss_on_explanation()\n",
    "            fidelity_loss_on_generated_data_singleclassifier[model_idx, instance_idx] = \\\n",
    "                explanation.get_fidelity_loss_on_generated_data()\n",
    "            fidelity_loss_on_kfold_mean_singleclassifier[model_idx, instance_idx] = \\\n",
    "                explanation.get_fidelity_loss_on_kfold(out=\"mean\")\n",
    "            fidelity_loss_on_kfold_std_singleclassifier[model_idx, instance_idx] = \\\n",
    "                explanation.get_fidelity_loss_on_kfold(out=\"std\")\n",
    "            fidelity_loss_distribution_quantiles_singleclassifier[model_idx, instance_idx, :] = \\\n",
    "                explanation.get_fidelity_loss_distribution(quantiles=bins_count)\n",
    "\n",
    "    postprocessor_singleclassifier = rp.ResultsProcessing(\n",
    "        models,\n",
    "        labels_count,\n",
    "        scores_for_surrogate_model_singleclassifier,\n",
    "        losses_for_surrogate_model_singleclassifier,\n",
    "        losses_mean_for_cv_model_singleclassifier,\n",
    "        losses_std_for_cv_model_singleclassifier,\n",
    "        fidelity_loss_on_explanation_singleclassifier,\n",
    "        fidelity_loss_on_generated_data_singleclassifier,\n",
    "        fidelity_loss_on_kfold_mean_singleclassifier,\n",
    "        fidelity_loss_on_kfold_std_singleclassifier,\n",
    "        fidelity_loss_distribution_quantiles_singleclassifier\n",
    "    )\n",
    "    postprocessor_singleclassifier.save_results(results_file_singleclassifier)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "postprocessor_singleclassifier.plot_scores_for_surrogate_model()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "postprocessor_singleclassifier.plot_losses_for_surrogate_model()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "postprocessor_singleclassifier.plot_fidelity_loss_on_explanation()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "postprocessor_singleclassifier.plot_fidelity_losses_on_generated_data()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "postprocessor_singleclassifier.plot_fidelity_loss_distribution(domain_unit=\"Quantiles\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}